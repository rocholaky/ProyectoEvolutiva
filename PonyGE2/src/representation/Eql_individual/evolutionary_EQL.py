import torch
from torch import nn
from representation.Eql_individual.network_parts import *

'''
here we define the the evolutionary EQL network where we can create different networks given a list of blocks generated by an evolutionary algorithm. 

'''

class evol_eql_layer(nn.Module):
    def __init__(self, in_features, block_list, out_features) -> None:
        super().__init__()
        # we define the input and output parameters:
        self.in_F = in_features
        self.out_F = out_features      

        # layer function list: 
        self.b_list = nn.ModuleList(block_list)
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")



    def forward(self, x):
        # we create an output to store:
        output = torch.zeros((x.shape[0], self.out_F)).to(self.device)

        # we itereate through the block list and add the output of each block.
        for block in self.b_list:
            output += block(x)
        # return the output.
        return output

    def to_string(self, threshold=1e-4, input_string=None):
        # name of the variables in the problem
        if input_string is None:
            named_variables = [f"x_{j}" for j in range(self.in_F)]
        else:
            named_variables = [f"{expr}" for expr in input_string]

        block_out = []
        for block in self.b_list:
            block_out.append(block.to_string(named_variables, threshold=threshold))


        result = []
        for i in range(self.out_F):
            res_per_block = []
            for block in block_out:
                res_per_block += [block[i]]
            result.append(res_per_block)
        return result


# network of evolutionary eql layers:
class evol_eql_nn(nn.Module):
    def __init__(self, in_features, layer_list, out_features):
        super().__init__()
        # definition of in_features and out_features:
        self.in_F = in_features
        self.out_F = out_features

        # layer list:
        self.layers = nn.ModuleList(layer_list)

        # set the device: 
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


    def forward(self, x):
        for layer in self.layer_list:
            x = layer(x)
        return x

    def to_string(self, threshold=1e-4, input_string=None):
        input_string = None
        for layer in self.layer_list:
            input_string = layer.to_string(threshold,input_string=input_string)
        return input_string


# network container, here a population of networks is stored in order to train in parallel:
class evol_eql_container(nn.Module):
    def __init__(self, list_of_ind, n_outputs):
        self.ind = nn.Module(list_of_ind)
        self.n_out = n_outputs
        # set the device: 
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")


    def forward(self, x):
        # we create an output to store:
        output = torch.zeros((x.shape[0], self.out_F)).to(self.device)
        for ind in self.ind:
            output += ind(x)
        return output

    def to_string(self, threshold=1e-4, input_string=None):
        output_string = []
        for ind in self.list_of_ind:
            output_string.append(ind.to_string(threshold))





        
if __name__ == '__main__':
    in_features = 2
    out_features = 1
    n_units = 2
    block_list = [power_Module(in_features, n_units, out_features), 
                    sin_Module(in_features, n_units, out_features)]
    evol_q = evol_eql_layer(in_features, block_list, out_features)
    print(list(evol_q.parameters()))